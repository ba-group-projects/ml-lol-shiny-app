library(shinydashboard)
library(shinyjs)

############################################################
library(caret)
library(tree)
library(randomForest)
library(dplyr)
library(rattle)
library(corrplot)
library(rpart)
library(rpart.plot)

# read data
# setwd("~/OneDrive/Documents/MyOversea/Cass Study/machine learning/MTP/MTP1/machine-learning-gp1")
setwd("/Volumes/GoogleDrive-117044175360160401988/My Drive/github/machine-learning-gp1")

lol.ori <- read.csv("high_diamond_ranked_10min.csv", header = TRUE)

# summary of data
str(lol.ori)
summary(lol.ori)

# pre-process data
sum(is.na(lol.ori)) # check missing values
lol.ori <- lol.ori[, -1]

set.seed(100)
lol.blue <- lol.ori[sample(which(lol.ori$blueWins == 1, ), 240), ]
lol.red <- lol.ori[sample(which(lol.ori$blueWins == 0, ), 240), ]
lol.sample <- rbind(lol.blue, lol.red)

# feature engineering
par(mfrow = c(1, 1))
blue.features <- lol.sample[, c(2:20)]
corrplot(cor(blue.features), tl.col = "black", diag = FALSE)
drop.blue.features <- c(
  "blueDragons", "blueHeralds", "blueKills",
  "blueDeaths", "blueAssists", "blueTotalGold",
  "blueAvgLevel", "blueTotalExperience", "blueExperienceDiff",
  "blueGoldPerMin", "blueTotalMinionsKilled"
)
blue.features <- blue.features[, !(colnames(blue.features) %in% drop.blue.features)]

red.features <- lol.sample[, -c(1, 2:20)]
corrplot(cor(blue.features, red.features), tl.col = "black", diag = TRUE)
drop.red.features <- c(
  "redFirstBlood", "redKills", "redDeaths", "redAssists",
  "redEliteMonsters", "redDragons", "redTotalGold",
  "redAvgLevel", "redTotalExperience", "redTotalMinionsKilled",
  "redGoldDiff", "redExperienceDiff", "redCSPerMin", "redGoldPerMin"
)
red.features <- red.features[, !(colnames(red.features) %in% drop.red.features)]
blueWins <- lol.sample$blueWins

lol <- cbind(blue.features, red.features, blueWins)
corrplot(cor(lol), tl.col = "black", diag = FALSE)
drop.more.features <- c(
  "blueWardsPlaced", "blueWardsDestroyed", "blueTowersDestroyed",
  "redWardsPlaced", "redWardsDestroyed", "redTowersDestroyed"
)
lol <- lol[, !(colnames(lol) %in% drop.more.features)]

# modify classification column
lol$blueWins[lol$blueWins == 1] <- "Blue"
lol$blueWins[lol$blueWins == 0] <- "Red"
lol$blueWins <- factor(lol$blueWins)

set.seed(100)
# random split to training and test set
# train.index = createDataPartition(lol$blueWins, p = 0.6, list = FALSE)
train.index <- createDataPartition(lol$blueWins, p = 0.7, list = FALSE)
train <- lol[train.index, ]
test <- lol[-train.index, ]


createTree <- function(train_data, min_split, min_bucket, max_depth) {
  # Takes a list of model variables (strings), a minimum split parameter
  # (int), a minimum bucket size parameter (int), and a maximum tree depth
  # parameter (int) as inputs and then returns an rpart classification tree
  # created with those parameters using Gini-indexes without any pruning.
  # create an rpart compatible formula for the model from the chosen vars
  # f <- paste("blueWins ~ ", paste(model_vars, collapse = " + "))
  # rpart is performs the split calculations and returns the tree
  tree <- rpart(
    # as.formula(f),
    "blueWins ~ .",
    method = "class", # sets it up as a classification problem
    data = train_data,
    parms = list(split = "gini"), # ensures rpart uses gini indexes
    minsplit = min_split,
    minbucket = min_bucket,
    maxdepth = max_depth,
    cp = 0 # complexity parameter, at zero prevents pruning on branches
  )

  return(tree)
}


evaluteTree <- function(tree) {
  # Takes a tree generated by rpart and a filename (string) as input and
  # then predicts the labels of the data in that file using the tree. It
  # returns a dataframe with two bool (0,1) columns: prediction and truth.
  trainX <- train[, -(length(train) + 1)]
  trainY <- train[, length(train)]
  testX <- test[, -(length(test) + 1)]
  testY <- test[, length(test)]
  pred.y.Train <- predict(tree, trainX, type = "class")
  pred.y.Test <- predict(tree, testX, type = "class")
  accuracyTrain <- mean(pred.y.Train == trainY)
  accuracyTest <- mean(pred.y.Test == testY)
  return(list(train.accuracy = accuracyTrain, test.accuracy = accuracyTest))
}

useTree <- function(tree,data) {
  # Takes a tree generated by rpart and a filename (string) as input and
  # then predicts the labels of the data in that file using the tree. It
  # returns a dataframe with two bool (0,1) columns: prediction and truth.

  prediction <- predict(tree, data, type = "class")
  results <- as.data.frame(prediction)
  results$truth <- data$blueWins

  return(results)
}

calcScores = function(results) {
    # Takes a results dataframe as input and then calculates scores for
    # accuracy, true negative rate, and true positive rate. It returns a
    # list of formatted strings detailing these results.

    results = table(results)
    # calculate the scores on which we'll judge our model to 2 decimal places
    accuracy = round(100 * (results[1] + results[4]) / sum(results), 2)
    true_neg = round(100 * results[1] / sum(results[1, ]), 2)
    true_pos = round(100 * results[4] / sum(results[2, ]), 2)

    # the collapse argument removes the spacing which would otherwise be there
    return(list(
        paste(c("Overall Accuracy: ",   accuracy, "%"), collapse = ""),
        paste(c("True Positive Rate: ", true_pos, "%"), collapse = ""),
        paste(c("True Negative Rate: ", true_neg, "%"), collapse = "")
    ))
}

resultsTable = function(results) {
    # Takes a results dataframe as input and then reconstructs and returns
    # a dataframe which has a similar layout to the command line interface
    # output of R's table(...) function.

    data = table(results)
    Outcomes = c("Predicted Blue Win", "Predicted Red Win", "Total")
    # reconstruct the columns of R's table(...) CLI display
    c1 = c(data[, 1], sum(data[, 1]))  # data[, 1] is a length 2 vector
    c2 = c(data[, 2], sum(data[, 1]))  # data[, 2] is a length 2 vector
    c3 = c(sum(data[, 1]), sum(data[2, ]), sum(data))

    # turn these columns back into a dataframe but with proper headers
    output = data.frame(Outcomes)
    output$"Actually Blue Win" = c1
    output$"Actually Red Win"     = c2
    output$"Total"             = c3

    return(output)
}
############################################################

# header

headerbar <- dashboardHeader(
  title = span(img(src = "download.png", height = 40), "LOL Diamond Rank Analytics"), # TODO solve broken picture
  # titleWidth = 300,
  tags$li(class = "dropdown", tags$style(".skin-blue .main-header .navbar {background-color: #111111;}"))
)

# sidebar
sidebar <- dashboardSidebar(
  sidebarMenu(
    menuItem("Introduction", tabName = "introduction", icon = icon("dashboard")),
    # menuItem("Model Selection",
    #   icon = icon("tree"), tabName = "modelSelection",

    menuItem("Decision Tree",
      tabName = "decisionTree", icon = icon("tree"),
      menuItem("Train", tabName = "decisionTreeTrain"),
      menuItem("Predict", tabName = "decisionTreePredict")
    ),
    menuItem("Random Forest",
      tabName = "randomForest", icon = icon("cubes"),
      menuItem("Train", tabName = "randomForestTrain"),
      menuItem("Predict", tabName = "randomForestPredict")
    )
    # menuItem("Prediction", tabName = "prediction", icon = icon("clock")),
    # menuItem("Lexicon", tabName = "lexicon", icon = icon("table")),
    # menuItem("Introduction Video", tabName = "introductionVideo", icon = icon("video"))
  )
)


# dashboardBody
dashboardContent <-
  dashboardBody(
    # # Boxes need to be put in a row (or column)
    # fluidRow(
    #   box(plotOutput("plot1", height = 600)),

    #   box(
    #     title = "Controls",
    #     sliderInput("slider", "Number of observations:", 1, 100, 50)
    #   )
    # ),
    tabItems(
      tabItem(tabName = "introduction"),
      # tabItem(tabName = "decisionTreeTrain"),
      tabItem(
        tabName = "decisionTreeTrain",
        fluidRow(
          box(
            fluidRow(
              plotOutput("decisionTreeTrainPlot", height = 600)
            ),
            fluidRow(
              column(
                6,
                # plotOutput("decisionTreeTrainPlot1", height = 600))
                h2("Training Results"),
                helpText(
                  "These are the measures of how good your model was",
                  "when it was ran on the training data set. Recall from",
                  "the lecture how we calculated each of these. Would",
                  "you prefer a false positive or false negative in the",
                  "context of spam detection?"
                ),
                # training accuracy, true positive, and true negative
                tagAppendAttributes(
                  textOutput("training_scores"),
                  # allow linebreaks between scores, larger font here
                  style = "white-space: pre-wrap; font-size: 17px;"
                ),
                br(),
                # training results table matches layout from presentation
                tableOutput("training_table")
              )
              ,
              column(
                6,
                h2("Test Results"),
                helpText(
                  "These are the measures of how good your model was",
                  "when it was ran on the test data set. Recall what",
                  "was said in lectures about how we interpret the",
                  "differences between measures these and the measures",
                  "from the training data."
                ),
                # test accuracy, true positive, and true negative
                tagAppendAttributes(
                  textOutput("test_scores"),
                  # allow linebreaks between scores, larger font here
                  style = "white-space: pre-wrap; font-size: 17px;"
                ),
                br(),
                # training results table matches layout from presentation
                tableOutput("test_table")
              )
            )),
            box(
              h3("Decision Tree"),
              helpText(
                "These controls are for setting the hyperparameter values",
                "which partly control the structure of the decision tree.",
                "The default values we've put in should create a fairly safe",
                "tree but try changing them if you're feeling adventurous."
              ),
              br(),              
              helpText(
                ""
              ),
              h4("Pick a Decision Tree"),
              helpText(
                ""
              ),
              # radioButtons("custOpt", "", c("Customize", "Optimize"),inline = TRUE,width='100%'), #TODO change the space
              radioButtons("custOpt", "", c("Optmized Tree", "Grow your own Tree!"),inline = TRUE,width='100%'),
              br(),
              actionButton(
                inputId = "trainModel",
                label = "Train Model",
                class = "btn-danger"#"btn-primary" # makes it blue!
              ),
              br(),
              br(),
              conditionalPanel(
                condition = "input.custOpt == 'Grow your own Tree!'",
                # box(
                  h4("Split Size"),
                  sliderInput(
                    inputId = "splitSize %",
                    label = '%', # label given in outer code
                    min = 0, # two is the smallest that could be split
                    max = 100, # chosen to not make the models too wild
                    value = 70 # defaults to not having an artifical minimum
                  ),
                  br(),
                  h4("Minimum Split"),
                  helpText(
                    "If at a given node N is below this value, that node cannot",
                    "be split any further: it is a terminal node of the tree."
                  ),
                  sliderInput(
                    inputId = "minSplit",
                    label = NULL, # label given in outer code
                    min = 2, # two is the smallest that could be split
                    max = 10, # chosen to not make the models too wild
                    value = 2 # defaults to not having an artifical minimum
                  ),
                  br(),
                  h4("Minimum Bucket Size"),
                  helpText(
                    "If creating a given split would cause N₁ or N₂ to fall below",
                    "this minimum, then that split isn't made part of the",
                    "decision tree."
                  ),
                  sliderInput(
                    inputId = "minBucket",
                    label = NULL, # label given in outer code
                    min = 1, # can't have buckets of size zero
                    max = 30, # rpart default is minbucket = 3*minsplit
                    value = 1 # defaults to not having an artifical minimum
                  ),
                  br(),
                  h4("Maximum Tree Depth"),
                  helpText(
                    "Control the maximum depth that the decision tree can reach.",
                    "Note that, depending on what features are being used and the",
                    "values of the other parameters, you may end up with a tree",
                    "much shallower than the maximum."
                  ),
                  sliderInput(
                    inputId = "maxDepth",
                    label = NULL, # label given in outer code
                    min = 2, # a min of 2 allows for at least one split
                    max = 30, # rpart can't do 31+ depth on 32-bit machines
                    value = 5 # chosen to not make the default too wild
                  )
                # )
              )              
            )
          )
        ),
        # ), #FIXME
        tabItem(
          tabName = "randomForest",
          fluidRow(
            box(plotOutput("randomForestPlot", height = 1000))
          )
        ),
        # TODO number of trees; randomize
        ##############################
        # prediction interaction part
        ##############################
        tabItem(
          tabName = "decisionTreePredict",
          fluidRow(
            box(plotOutput("plot1", height = 2500)),
            box(
              title = "Controls",
              # radioButtons("firstBlood", "First Blood", c("Blue", "Red")),
              # radioButtons("herald", "Herald", c("Blue", "Red")),
              # sliderInput("blueWardsPlaced", "Blue wards placed", 0, 60, 20),
              # sliderInput("blueWardsDestroyed", "Red wards placed", 0, 120, 20),
              # sliderInput("blueELiteMonsters", "Blue Elite Monsters", 0, 2, 1),
              # sliderInput("blueTowersDestroyed", "Blue Towers Destroyed", 0, 1, 1),
              # sliderInput("blueTotalJungleMinionsKilled", "Blue Total Jungle Minions Killed", 0, 80, 20),
              # sliderInput("blueTotalGold", "Blue Total Gold", -10000, 10000, 0),
              # sliderInput("blueMinionKillsPerMin", "Blue Minion Kills Per Min", 10, 30, 20),
              # sliderInput("redWardsPlaced", "Red wards placed", 0, 60, 20),
              # sliderInput("redWardsPlaced", "Red wards placed", 0, 60, 20),
              # sliderInput("redTowersDestroyed", "Red Towers Destroyed", 0, 1, 1),
              # sliderInput("redTotalJungleMinionsKilled", "Red Total Jungle Minions Killed", 0, 80, 20),
              # sliderInput("redTotalGold", "Red Total Gold", -10000, 10000, 0)
              div(id="placeholder"),
              actionButton("addLine", "Add Line")
            )
          )
        )
        #       tabItem(
        #         tabName = "lexicon",
        #         HTML('<!DOCTYPE html>
        # <html>
        # <head>
        #   <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        #   <script type="application/shiny-singletons"></script>
        #   <script type="application/html-dependencies">jquery[3.6.0];shiny-css[1.7.1];shiny-javascript[1.7.1]</script>
        #   <head>
        #     <link href="shared/shiny.min.css" rel="stylesheet" />
        #     <script src="shared/shiny.min.js"></script>
        #     </head>
        #     <body>
        #         <h1>Lexicon</h1>
        #         <table>
        #         <tr>
        #             <th>Name</th>
        #             <th>Explanation</th>
        #           </tr>
        #           <tr>
        #             <td>Alfreds Futterkiste</td>
        #             <td>Maria Anders</td>
        #           </tr>
        #         </table>
        #         </body>>
        # </html>')
        #       ),
        # tabItem(
        #   tabName = "introductionVideo",
        #   HTML('<iframe width="560" height="315" src="https://www.youtube.com/embed/0uyLRPmmYPk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>')
        # ),
      ),
      tags$head(tags$style(HTML("
            /* logo */
            .skin-blue .main-header .logo {
                                  background-color: #111111;
                                  };
    #         /* whole page */
    #         .box {margin-top: 2px;margin-left: 0px; margin-right: 0px; margin-bottom:2px;padding:-10px};
    # div {padding: 0 !important;}
                                  ")))
    )


# whole Ui
ui <- dashboardPage(
  # useShinyjs(),
  # extendShinyjs(text = jsToggleFS),
  headerbar,
  sidebar,
  dashboardContent
)

server <- function(input, output, session) {
  set.seed(122)
  # histdata <- rnorm(500)
  # output$randomForestPlot <- renderPlot(hist(histdata, plot = FALSE), "plot1")
  # decisionTree <- createTree(train, observe(input$minSplit), observe(input$minBucket), observe(input$maxDepth))
  decisionTree <- eventReactive(
    eventExpr = input$trainModel,
    valueExpr = createTree(train, input$minSplit, input$minBucket, input$maxDepth)
  )
  output$decisionTreeTrainPlot1 <- renderPlot(
    rpart.plot(decisionTree(), box.palette = "BuRd")
  )
  output$decisionTreeTrainPlot <- renderPlot(
    rpart.plot(decisionTree(), box.palette = "BuRd")
  )

  ##############################
  #### eventReactive############
  ##############################

  # regenerate training results every time createModel is pressed
  training_results <- eventReactive(
    eventExpr = input$trainModel,
    valueExpr = useTree(decisionTree(),train)
  )
  test_results <- eventReactive(
    eventExpr = input$trainModel,
    valueExpr = useTree(decisionTree(),test)
  )

  ##############################
  #### observeEvent############
  ##############################
  observeEvent(input$addLine, {
    new_id <- paste("row", input$addLine, sep = "_")
    insertUI(
      selector = "#placeholder",
      where = "beforeBegin",
      ui = sliderInput("blueWardsDestroyed", "Red wards placed", 0, 120, 20))}
    )
  
  # # obvervation for customizer and optimizer
  # observeEvent(input$custOpt, {
  #   if (input$custOpt == 'Customizer'){
  #     shinyjs::show(id = "customizer-optimizer")
  #   }else {
  #     shinyjs::hidden(id = "customizer-optimizer")
  #   }
  # })
  
  output$training_scores <- renderText(
    paste(calcScores(training_results()), collapse = "\n")
  )
  output$test_scores <- renderText(
    paste(calcScores(test_results()), collapse = "\n")
  )
  output$training_table = renderTable(
        resultsTable(training_results()),
        align = "lccc",  # left-align first column, centre rest
        striped = TRUE
    )
    output$test_table = renderTable(
        resultsTable(test_results()),
        align = "lccc",  # left-align first column, centre rest
        striped = TRUE
    )
  # height = 1000,
  # width = 1000,
  # xlab = "",
  # ylab = "",
  # main = "Decision Tree"
}

shinyApp(ui, server)