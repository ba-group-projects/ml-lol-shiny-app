<!DOCTYPE html>
<html>  

<div style="margin: 4%">
<h2>
    Introduction:
</h2>
<p>
    <h3>Classification Model</h3>
    <br>
    <br>
    <p>The aim of this app is to explain how decision trees and random forest works in classification problems. We aim to showcase this by creating a classification model to predict the winner of League of Legends, an online video game. Users will be able to play around with the model’s hyperparameters to see its effect on the model performance.
    
    </p>
    
    
    <h3>What Is A Decision tree</h3>
    <br>
    <br>
    Decision trees perform a classification on data in a hierarchical structure by observing the key differentiating features on the classification data. The path is segregated into binary “yes”, “no” decisions at each level leading to another question and ultimately the result. Each question is regarded as a node, with the split becoming “branches” and the “leaves” representing the end of each point.  
    
    <img src="randomforest.gif">
    <h3>What Is A Random Forest</h3>
    <br>
    <br>
    
    Random forests is a modified approach to bagging (bootstrap sampling that averages the aggregate of individual models), in which an algorithm inspects a random subset of features in the data at each split in the learning process, rather than all features seen in bagging. This is done to avoid correlation between the trees. Using multiple bootstrapped samples of the original dataset reduces variance, resulting in lower overfitting. 
     
</br>
</div>
</html>